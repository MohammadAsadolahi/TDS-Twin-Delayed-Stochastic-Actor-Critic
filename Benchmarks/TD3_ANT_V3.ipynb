{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a591e185",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-16T16:11:14.687544Z",
     "iopub.status.busy": "2023-06-16T16:11:14.686996Z",
     "iopub.status.idle": "2023-06-16T16:14:10.906949Z",
     "shell.execute_reply": "2023-06-16T16:14:10.905222Z"
    },
    "papermill": {
     "duration": 176.230528,
     "end_time": "2023-06-16T16:14:10.910556",
     "exception": false,
     "start_time": "2023-06-16T16:11:14.680028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting templates from packages: 100%\r\n",
      "(Reading database ... 106398 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-libx11-6_2%3a1.6.9-2ubuntu1.5_amd64.deb ...\r\n",
      "Unpacking libx11-6:amd64 (2:1.6.9-2ubuntu1.5) over (2:1.6.9-2ubuntu1.2) ...\r\n",
      "Selecting previously unselected package libwayland-server0:amd64.\r\n",
      "Preparing to unpack .../01-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\r\n",
      "Selecting previously unselected package libgbm1:amd64.\r\n",
      "Preparing to unpack .../02-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libegl-mesa0:amd64.\r\n",
      "Preparing to unpack .../03-libegl-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libegl1:amd64.\r\n",
      "Preparing to unpack .../04-libegl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package xorg-sgml-doctools.\r\n",
      "Preparing to unpack .../05-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\r\n",
      "Unpacking xorg-sgml-doctools (1:1.11-1) ...\r\n",
      "Selecting previously unselected package x11proto-dev.\r\n",
      "Preparing to unpack .../06-x11proto-dev_2019.2-1ubuntu1_all.deb ...\r\n",
      "Unpacking x11proto-dev (2019.2-1ubuntu1) ...\r\n",
      "Selecting previously unselected package x11proto-core-dev.\r\n",
      "Preparing to unpack .../07-x11proto-core-dev_2019.2-1ubuntu1_all.deb ...\r\n",
      "Unpacking x11proto-core-dev (2019.2-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libxau-dev:amd64.\r\n",
      "Preparing to unpack .../08-libxau-dev_1%3a1.0.9-0ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\r\n",
      "Selecting previously unselected package libxdmcp-dev:amd64.\r\n",
      "Preparing to unpack .../09-libxdmcp-dev_1%3a1.1.3-0ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\r\n",
      "Selecting previously unselected package xtrans-dev.\r\n",
      "Preparing to unpack .../10-xtrans-dev_1.4.0-1_all.deb ...\r\n",
      "Unpacking xtrans-dev (1.4.0-1) ...\r\n",
      "Selecting previously unselected package libpthread-stubs0-dev:amd64.\r\n",
      "Preparing to unpack .../11-libpthread-stubs0-dev_0.4-1_amd64.deb ...\r\n",
      "Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
      "Selecting previously unselected package libxcb1-dev:amd64.\r\n",
      "Preparing to unpack .../12-libxcb1-dev_1.14-2_amd64.deb ...\r\n",
      "Unpacking libxcb1-dev:amd64 (1.14-2) ...\r\n",
      "Selecting previously unselected package libx11-dev:amd64.\r\n",
      "Preparing to unpack .../13-libx11-dev_2%3a1.6.9-2ubuntu1.5_amd64.deb ...\r\n",
      "Unpacking libx11-dev:amd64 (2:1.6.9-2ubuntu1.5) ...\r\n",
      "Selecting previously unselected package libglx-dev:amd64.\r\n",
      "Preparing to unpack .../14-libglx-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglx-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgl-dev:amd64.\r\n",
      "Preparing to unpack .../15-libgl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libegl-dev:amd64.\r\n",
      "Preparing to unpack .../16-libegl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgles1:amd64.\r\n",
      "Preparing to unpack .../17-libgles1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgles2:amd64.\r\n",
      "Preparing to unpack .../18-libgles2_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgles-dev:amd64.\r\n",
      "Preparing to unpack .../19-libgles-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libopengl0:amd64.\r\n",
      "Preparing to unpack .../20-libopengl0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libopengl-dev:amd64.\r\n",
      "Preparing to unpack .../21-libopengl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libglvnd-dev:amd64.\r\n",
      "Preparing to unpack .../22-libglvnd-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgl1-mesa-dev:amd64.\r\n",
      "Preparing to unpack .../23-libgl1-mesa-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libglew2.1:amd64.\r\n",
      "Preparing to unpack .../24-libglew2.1_2.1.0-4_amd64.deb ...\r\n",
      "Unpacking libglew2.1:amd64 (2.1.0-4) ...\r\n",
      "Selecting previously unselected package libglu1-mesa:amd64.\r\n",
      "Preparing to unpack .../25-libglu1-mesa_9.0.1-1build1_amd64.deb ...\r\n",
      "Unpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\r\n",
      "Selecting previously unselected package libglu1-mesa-dev:amd64.\r\n",
      "Preparing to unpack .../26-libglu1-mesa-dev_9.0.1-1build1_amd64.deb ...\r\n",
      "Unpacking libglu1-mesa-dev:amd64 (9.0.1-1build1) ...\r\n",
      "Selecting previously unselected package libglew-dev:amd64.\r\n",
      "Preparing to unpack .../27-libglew-dev_2.1.0-4_amd64.deb ...\r\n",
      "Unpacking libglew-dev:amd64 (2.1.0-4) ...\r\n",
      "Selecting previously unselected package libglfw3:amd64.\r\n",
      "Preparing to unpack .../28-libglfw3_3.3.2-1_amd64.deb ...\r\n",
      "Unpacking libglfw3:amd64 (3.3.2-1) ...\r\n",
      "Selecting previously unselected package patchelf.\r\n",
      "Preparing to unpack .../29-patchelf_0.10-2build1_amd64.deb ...\r\n",
      "Unpacking patchelf (0.10-2build1) ...\r\n",
      "Selecting previously unselected package libosmesa6:amd64.\r\n",
      "Preparing to unpack .../30-libosmesa6_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libosmesa6-dev:amd64.\r\n",
      "Preparing to unpack .../31-libosmesa6-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\r\n",
      "Setting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
      "Setting up libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up xtrans-dev (1.4.0-1) ...\r\n",
      "Setting up libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglew2.1:amd64 (2.1.0-4) ...\r\n",
      "Setting up libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libx11-6:amd64 (2:1.6.9-2ubuntu1.5) ...\r\n",
      "Setting up xorg-sgml-doctools (1:1.11-1) ...\r\n",
      "Setting up libglu1-mesa:amd64 (9.0.1-1build1) ...\r\n",
      "Setting up libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up patchelf (0.10-2build1) ...\r\n",
      "Setting up libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up x11proto-dev (2019.2-1ubuntu1) ...\r\n",
      "Setting up libglfw3:amd64 (3.3.2-1) ...\r\n",
      "Setting up libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\r\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\r\n",
      "Setting up x11proto-core-dev (2019.2-1ubuntu1) ...\r\n",
      "Setting up libxcb1-dev:amd64 (1.14-2) ...\r\n",
      "Setting up libx11-dev:amd64 (2:1.6.9-2ubuntu1.5) ...\r\n",
      "Setting up libglx-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libgl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libegl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglu1-mesa-dev:amd64 (9.0.1-1build1) ...\r\n",
      "Setting up libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglew-dev:amd64 (2.1.0-4) ...\r\n",
      "Setting up libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Processing triggers for man-db (2.9.1-1) ...\r\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\r\n",
      "Collecting mujoco-py<2.2,>=2.1\r\n",
      "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: fasteners~=0.15 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (0.17.3)\r\n",
      "Collecting glfw>=1.4.0\r\n",
      "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.1.2 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (2.19.3)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (1.21.6)\r\n",
      "Requirement already satisfied: cffi>=1.10 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (1.15.0)\r\n",
      "Requirement already satisfied: Cython>=0.27.2 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (0.29.33)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1) (2.21)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.7/site-packages (from imageio>=2.1.2->mujoco-py<2.2,>=2.1) (9.1.1)\r\n",
      "Installing collected packages: glfw, mujoco-py\r\n",
      "Successfully installed glfw-2.5.9 mujoco-py-2.1.2.14\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCompiling /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.pyx because it changed.\n",
      "[1/1] Cythonizing /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.pyx\n",
      "running build_ext\n",
      "building 'mujoco_py.cymj' extension\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/opt/conda/lib/python3.7/site-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I/opt/conda/include/python3.7m -c /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.c -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.o -fopenmp -w\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/opt/conda/lib/python3.7/site-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I/opt/conda/include/python3.7m -c /opt/conda/lib/python3.7/site-packages/mujoco_py/gl/osmesashim.c -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py\n",
      "gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl/osmesashim.o -L/root/.mujoco/mujoco210/bin -Wl,-R/root/.mujoco/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py/cymj.cpython-37m-x86_64-linux-gnu.so -fopenmp\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import Math, HTML\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "if not os.path.exists('.mujoco_setup_complete'):\n",
    "  # Get the prereqs\n",
    "  !apt-get -qq update\n",
    "  !apt-get -qq install -y libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev libglew-dev patchelf\n",
    "  # Get Mujoco\n",
    "  !mkdir ~/.mujoco\n",
    "  !wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O mujoco.tar.gz\n",
    "  !tar -zxf mujoco.tar.gz -C \"$HOME/.mujoco\"\n",
    "  !rm mujoco.tar.gz\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  !echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.mujoco/mujoco210/bin' >> ~/.bashrc \n",
    "  !echo 'export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libGLEW.so' >> ~/.bashrc \n",
    "  # THE ANNOYING ONE, FORCE IT INTO LDCONFIG SO WE ACTUALLY GET ACCESS TO IT THIS SESSION\n",
    "  !echo \"/root/.mujoco/mujoco210/bin\" > /etc/ld.so.conf.d/mujoco_ld_lib_path.conf\n",
    "  !ldconfig\n",
    "  # Install Mujoco-py\n",
    "  !pip3 install -U 'mujoco-py<2.2,>=2.1'\n",
    "  # run once\n",
    "  !touch .mujoco_setup_complete\n",
    "\n",
    "try:\n",
    "  if _mujoco_run_once:\n",
    "    pass\n",
    "except NameError:\n",
    "  _mujoco_run_once = False\n",
    "if not _mujoco_run_once:\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  try:\n",
    "    os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + ':/root/.mujoco/mujoco210/bin'\n",
    "  except KeyError:\n",
    "    os.environ['LD_LIBRARY_PATH']='/root/.mujoco/mujoco210/bin'\n",
    "  try:\n",
    "    os.environ['LD_PRELOAD']=os.environ['LD_PRELOAD'] + ':/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  except KeyError:\n",
    "    os.environ['LD_PRELOAD']='/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  # presetup so we don't see output on first env initialization\n",
    "  import mujoco_py\n",
    "  _mujoco_run_once = True\n",
    "#source of this code block : https://gist.github.com/BuildingAtom/3119ac9c595324c8001a7454f23bf8c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4915ca76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T16:14:10.940710Z",
     "iopub.status.busy": "2023-06-16T16:14:10.938897Z",
     "iopub.status.idle": "2023-06-16T16:14:39.112048Z",
     "shell.execute_reply": "2023-06-16T16:14:39.110688Z"
    },
    "papermill": {
     "duration": 28.190687,
     "end_time": "2023-06-16T16:14:39.114820",
     "exception": false,
     "start_time": "2023-06-16T16:14:10.924133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box2d-py\r\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.6/448.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: box2d-py\r\n",
      "Successfully installed box2d-py-2.3.8\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: gym[Box_2D] in /opt/conda/lib/python3.7/site-packages (0.26.2)\r\n",
      "\u001b[33mWARNING: gym 0.26.2 does not provide the extra 'box_2d'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym[Box_2D]) (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from gym[Box_2D]) (1.21.6)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/conda/lib/python3.7/site-packages (from gym[Box_2D]) (6.0.0)\r\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from gym[Box_2D]) (0.0.8)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym[Box_2D]) (3.8.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym[Box_2D]) (4.1.1)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pdb\n",
    "import copy\n",
    "!pip3 install box2d-py\n",
    "!pip3 install gym[Box_2D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6453b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T16:14:39.147303Z",
     "iopub.status.busy": "2023-06-16T16:14:39.145995Z",
     "iopub.status.idle": "2023-06-16T16:14:39.155545Z",
     "shell.execute_reply": "2023-06-16T16:14:39.154386Z"
    },
    "papermill": {
     "duration": 0.0291,
     "end_time": "2023-06-16T16:14:39.158288",
     "exception": false,
     "start_time": "2023-06-16T16:14:39.129188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_update(target, source, tau):\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\ttarget_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\ttarget_param.data.copy_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6e33bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T16:14:39.188547Z",
     "iopub.status.busy": "2023-06-16T16:14:39.188127Z",
     "iopub.status.idle": "2023-06-16T16:14:39.202259Z",
     "shell.execute_reply": "2023-06-16T16:14:39.200957Z"
    },
    "papermill": {
     "duration": 0.032357,
     "end_time": "2023-06-16T16:14:39.204811",
     "exception": false,
     "start_time": "2023-06-16T16:14:39.172454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self,input_shape, n_actions,max_size=int(1e6)):\n",
    "        self.memory_size = max_size\n",
    "        self.memory_counter = 0\n",
    "        self.state = np.zeros((self.memory_size, input_shape))\n",
    "        self.state_ = np.zeros((self.memory_size, input_shape))\n",
    "        self.action = np.zeros((self.memory_size, n_actions))\n",
    "        self.reward = np.zeros(self.memory_size)\n",
    "        self.done = np.zeros(self.memory_size)\n",
    "\n",
    "    def add(self, state, action, reward, state_, done):\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.state[index] = state\n",
    "        self.state_[index] = state_\n",
    "        self.action[index] = action\n",
    "        self.reward[index] = reward\n",
    "        self.done[index] = done\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        max_memory = min(self.memory_counter, self.memory_size)\n",
    "\n",
    "        batch = np.random.choice(max_memory, batch_size)\n",
    "\n",
    "        state = self.state[batch]\n",
    "        action= self.action[batch]\n",
    "        reward = self.reward[batch]\n",
    "        state_ = self.state_[batch]\n",
    "        done = self.done[batch]\n",
    "        return state, action, reward, state_, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c248dd0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T16:14:39.235938Z",
     "iopub.status.busy": "2023-06-16T16:14:39.235519Z",
     "iopub.status.idle": "2023-06-16T16:14:39.282978Z",
     "shell.execute_reply": "2023-06-16T16:14:39.281895Z"
    },
    "papermill": {
     "duration": 0.066561,
     "end_time": "2023-06-16T16:14:39.285889",
     "exception": false,
     "start_time": "2023-06-16T16:14:39.219328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Implementation of Twin Delayed Deep Deterministic Policy Gradients (TD3)\n",
    "# Paper: https://arxiv.org/abs/1802.09477\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim, max_action):\n",
    "\t\tsuper(Actor, self).__init__()\n",
    "\n",
    "\t\tself.l1 = nn.Linear(state_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, action_dim)\n",
    "\n",
    "\t\tself.max_action = max_action\n",
    "\n",
    "\n",
    "\tdef forward(self, state):\n",
    "\t\ta = F.relu(self.l1(state))\n",
    "\t\ta = F.relu(self.l2(a))\n",
    "\t\treturn self.max_action * torch.tanh(self.l3(a))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim):\n",
    "\t\tsuper(Critic, self).__init__()\n",
    "\n",
    "\t\t# Q1 architecture\n",
    "\t\tself.l1 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, 1)\n",
    "\n",
    "\t\t# Q2 architecture\n",
    "\t\tself.l4 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l5 = nn.Linear(256, 256)\n",
    "\t\tself.l6 = nn.Linear(256, 1)\n",
    "\n",
    "\n",
    "\tdef forward(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\n",
    "\t\tq2 = F.relu(self.l4(sa))\n",
    "\t\tq2 = F.relu(self.l5(q2))\n",
    "\t\tq2 = self.l6(q2)\n",
    "\t\treturn q1, q2\n",
    "\n",
    "\n",
    "\tdef Q1(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\t\treturn q1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TD3(object):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tstate_dim,\n",
    "\t\taction_dim,\n",
    "\t\tmax_action,\n",
    "\t\tdiscount=0.99,\n",
    "\t\ttau=0.005,\n",
    "\t\tpolicy_noise=0.2,\n",
    "\t\tnoise_clip=0.5,\n",
    "\t\tpolicy_freq=2\n",
    "\t):\n",
    "\n",
    "\t\tself.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)\n",
    "\t\tself.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "\n",
    "\t\tself.critic = Critic(state_dim, action_dim).to(device)\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\t\tself.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=3e-4)\n",
    "\n",
    "\t\tself.max_action = max_action\n",
    "\t\tself.discount = discount\n",
    "\t\tself.tau = tau\n",
    "\t\tself.policy_noise = policy_noise\n",
    "\t\tself.noise_clip = noise_clip\n",
    "\t\tself.policy_freq = policy_freq\n",
    "\n",
    "\t\tself.total_it = 0\n",
    "\n",
    "\n",
    "\tdef select_action(self, state):\n",
    "\t\tstate = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "\t\treturn self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "\n",
    "\tdef train(self, replay_buffer, batch_size=100):\n",
    "\t\tif replay_buffer.memory_size<batch_size:\n",
    "\t\t\treturn\n",
    "\t\tself.total_it += 1\n",
    "\t\t# Sample replay buffer\n",
    "\t\tstate, action, reward,next_state, not_done = replay_buffer.sample(batch_size)\n",
    "\t\treward = T.tensor(reward, dtype=T.float)\n",
    "\t\tnot_done = T.tensor(not_done,dtype=T.float)\n",
    "\t\tnext_state = T.tensor(next_state, dtype=T.float)\n",
    "\t\tstate = T.tensor(state, dtype=T.float)\n",
    "\t\taction = T.tensor(action, dtype=T.float)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# Select action according to policy and add clipped noise\n",
    "\t\t\tnoise = (\n",
    "\t\t\t\ttorch.randn_like(action) * self.policy_noise\n",
    "\t\t\t).clamp(-self.noise_clip, self.noise_clip)\n",
    "\n",
    "\t\t\tnext_action = (\n",
    "\t\t\t\tself.actor_target(next_state) + noise\n",
    "\t\t\t).clamp(-self.max_action, self.max_action)\n",
    "\n",
    "\t\t\t# Compute the target Q value\n",
    "\t\t\ttarget_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\t\t\ttarget_Q = torch.squeeze(torch.min(target_Q1, target_Q2))\n",
    "\t\t\ttarget_Q = reward + not_done * self.discount * target_Q\n",
    "\t\t# Get current Q estimates\n",
    "\t\tcurrent_Q1, current_Q2 = self.critic(state, action)\n",
    "\n",
    "\t\t# Compute critic loss\n",
    "\t\tcritic_loss = F.mse_loss(torch.squeeze(current_Q1), target_Q) + F.mse_loss(torch.squeeze(current_Q2), target_Q)\n",
    "\n",
    "\t\t# Optimize the critic\n",
    "\t\tself.critic_optimizer.zero_grad()\n",
    "\t\tcritic_loss.backward()\n",
    "\t\tself.critic_optimizer.step()\n",
    "\n",
    "\t\t# Delayed policy updates\n",
    "\t\tif self.total_it % self.policy_freq == 0:\n",
    "\n",
    "\t\t\t# Compute actor losse\n",
    "\t\t\tactor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
    "\n",
    "\t\t\t# Optimize the actor\n",
    "\t\t\tself.actor_optimizer.zero_grad()\n",
    "\t\t\tactor_loss.backward()\n",
    "\t\t\tself.actor_optimizer.step()\n",
    "\n",
    "\t\t\t# Update the frozen target models\n",
    "\t\t\tfor param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\t\t\tfor param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "\tdef save(self, filename):\n",
    "\t\ttorch.save(self.critic.state_dict(), filename + \"_critic\")\n",
    "\t\ttorch.save(self.critic_optimizer.state_dict(), filename + \"_critic_optimizer\")\n",
    "\n",
    "\t\ttorch.save(self.actor.state_dict(), filename + \"_actor\")\n",
    "\t\ttorch.save(self.actor_optimizer.state_dict(), filename + \"_actor_optimizer\")\n",
    "\n",
    "\n",
    "\tdef load(self, filename):\n",
    "\t\tself.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
    "\t\tself.critic_optimizer.load_state_dict(torch.load(filename + \"_critic_optimizer\"))\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\n",
    "\t\tself.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
    "\t\tself.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_optimizer\"))\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77332f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T16:14:39.316530Z",
     "iopub.status.busy": "2023-06-16T16:14:39.316104Z",
     "iopub.status.idle": "2023-06-16T19:19:54.650551Z",
     "shell.execute_reply": "2023-06-16T19:19:54.649555Z"
    },
    "papermill": {
     "duration": 11115.353102,
     "end_time": "2023-06-16T19:19:54.653407",
     "exception": false,
     "start_time": "2023-06-16T16:14:39.300305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/envs/registration.py:556: UserWarning: \u001b[33mWARN: The environment Ant-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n",
      "/opt/conda/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py:191: UserWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  \"This version of the mujoco environments depends \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 10 episodes: 997.094  time step5000\n",
      "Evaluation over 10 episodes: 995.649  time step10000\n",
      "Evaluation over 10 episodes: 901.256  time step15000\n",
      "Evaluation over 10 episodes: 765.532  time step20000\n",
      "Evaluation over 10 episodes: 291.046  time step25000\n",
      "Evaluation over 10 episodes: 647.599  time step30000\n",
      "Evaluation over 10 episodes: 768.775  time step35000\n",
      "Evaluation over 10 episodes: 833.591  time step40000\n",
      "Evaluation over 10 episodes: 858.405  time step45000\n",
      "Evaluation over 10 episodes: 875.778  time step50000\n",
      "Evaluation over 10 episodes: 846.627  time step55000\n",
      "Evaluation over 10 episodes: 867.015  time step60000\n",
      "Evaluation over 10 episodes: 890.383  time step65000\n",
      "Evaluation over 10 episodes: 900.282  time step70000\n",
      "Evaluation over 10 episodes: 893.936  time step75000\n",
      "Evaluation over 10 episodes: 896.025  time step80000\n",
      "Evaluation over 10 episodes: 879.941  time step85000\n",
      "Evaluation over 10 episodes: 781.528  time step90000\n",
      "Evaluation over 10 episodes: 489.535  time step95000\n",
      "Evaluation over 10 episodes: 713.615  time step100000\n",
      "Evaluation over 10 episodes: 867.660  time step105000\n",
      "Evaluation over 10 episodes: 861.654  time step110000\n",
      "Evaluation over 10 episodes: 889.066  time step115000\n",
      "Evaluation over 10 episodes: 930.966  time step120000\n",
      "Evaluation over 10 episodes: 896.223  time step125000\n",
      "Evaluation over 10 episodes: 905.776  time step130000\n",
      "Evaluation over 10 episodes: 925.399  time step135000\n",
      "Evaluation over 10 episodes: 929.618  time step140000\n",
      "Evaluation over 10 episodes: 934.207  time step145000\n",
      "Evaluation over 10 episodes: 955.782  time step150000\n",
      "Evaluation over 10 episodes: 856.382  time step155000\n",
      "Evaluation over 10 episodes: 944.526  time step160000\n",
      "Evaluation over 10 episodes: 917.493  time step165000\n",
      "Evaluation over 10 episodes: 941.734  time step170000\n",
      "Evaluation over 10 episodes: 743.046  time step175000\n",
      "Evaluation over 10 episodes: 793.811  time step180000\n",
      "Evaluation over 10 episodes: 941.970  time step185000\n",
      "Evaluation over 10 episodes: 943.040  time step190000\n",
      "Evaluation over 10 episodes: 1025.559  time step195000\n",
      "Evaluation over 10 episodes: 1047.992  time step200000\n",
      "Evaluation over 10 episodes: 939.705  time step205000\n",
      "Evaluation over 10 episodes: 1174.229  time step210000\n",
      "Evaluation over 10 episodes: 964.610  time step215000\n",
      "Evaluation over 10 episodes: 959.782  time step220000\n",
      "Evaluation over 10 episodes: 1213.756  time step225000\n",
      "Evaluation over 10 episodes: 1052.707  time step230000\n",
      "Evaluation over 10 episodes: 867.329  time step235000\n",
      "Evaluation over 10 episodes: 1346.355  time step240000\n",
      "Evaluation over 10 episodes: 821.138  time step245000\n",
      "Evaluation over 10 episodes: 1207.964  time step250000\n",
      "Evaluation over 10 episodes: 1343.409  time step255000\n",
      "Evaluation over 10 episodes: 1307.119  time step260000\n",
      "Evaluation over 10 episodes: 1252.732  time step265000\n",
      "Evaluation over 10 episodes: 1408.686  time step270000\n",
      "Evaluation over 10 episodes: 1413.183  time step275000\n",
      "Evaluation over 10 episodes: 1384.537  time step280000\n",
      "Evaluation over 10 episodes: 1451.011  time step285000\n",
      "Evaluation over 10 episodes: 1564.574  time step290000\n",
      "Evaluation over 10 episodes: 1680.884  time step295000\n",
      "Evaluation over 10 episodes: 1383.381  time step300000\n",
      "Evaluation over 10 episodes: 1842.403  time step305000\n",
      "Evaluation over 10 episodes: 1674.865  time step310000\n",
      "Evaluation over 10 episodes: 1732.935  time step315000\n",
      "Evaluation over 10 episodes: 1510.000  time step320000\n",
      "Evaluation over 10 episodes: 1818.381  time step325000\n",
      "Evaluation over 10 episodes: 1187.478  time step330000\n",
      "Evaluation over 10 episodes: 1850.202  time step335000\n",
      "Evaluation over 10 episodes: 1783.662  time step340000\n",
      "Evaluation over 10 episodes: 1637.961  time step345000\n",
      "Evaluation over 10 episodes: 1736.971  time step350000\n",
      "Evaluation over 10 episodes: 1988.809  time step355000\n",
      "Evaluation over 10 episodes: 1712.356  time step360000\n",
      "Evaluation over 10 episodes: 2039.640  time step365000\n",
      "Evaluation over 10 episodes: 1771.766  time step370000\n",
      "Evaluation over 10 episodes: 1391.809  time step375000\n",
      "Evaluation over 10 episodes: 2010.644  time step380000\n",
      "Evaluation over 10 episodes: 1538.719  time step385000\n",
      "Evaluation over 10 episodes: 1564.091  time step390000\n",
      "Evaluation over 10 episodes: 1695.869  time step395000\n",
      "Evaluation over 10 episodes: 2257.190  time step400000\n",
      "Evaluation over 10 episodes: 1702.856  time step405000\n",
      "Evaluation over 10 episodes: 1958.268  time step410000\n",
      "Evaluation over 10 episodes: 2209.257  time step415000\n",
      "Evaluation over 10 episodes: 1336.239  time step420000\n",
      "Evaluation over 10 episodes: 2215.750  time step425000\n",
      "Evaluation over 10 episodes: 2040.445  time step430000\n",
      "Evaluation over 10 episodes: 2188.739  time step435000\n",
      "Evaluation over 10 episodes: 2411.683  time step440000\n",
      "Evaluation over 10 episodes: 2143.984  time step445000\n",
      "Evaluation over 10 episodes: 2485.889  time step450000\n",
      "Evaluation over 10 episodes: 2226.159  time step455000\n",
      "Evaluation over 10 episodes: 2619.868  time step460000\n",
      "Evaluation over 10 episodes: 2660.018  time step465000\n",
      "Evaluation over 10 episodes: 2628.538  time step470000\n",
      "Evaluation over 10 episodes: 2861.758  time step475000\n",
      "Evaluation over 10 episodes: 2569.396  time step480000\n",
      "Evaluation over 10 episodes: 2479.062  time step485000\n",
      "Evaluation over 10 episodes: 2824.241  time step490000\n",
      "Evaluation over 10 episodes: 2364.798  time step495000\n",
      "Evaluation over 10 episodes: 2845.743  time step500000\n",
      "Evaluation over 10 episodes: 2796.200  time step505000\n",
      "Evaluation over 10 episodes: 2821.750  time step510000\n",
      "Evaluation over 10 episodes: 2060.929  time step515000\n",
      "Evaluation over 10 episodes: 2972.776  time step520000\n",
      "Evaluation over 10 episodes: 2177.692  time step525000\n",
      "Evaluation over 10 episodes: 2244.509  time step530000\n",
      "Evaluation over 10 episodes: 3075.856  time step535000\n",
      "Evaluation over 10 episodes: 3173.211  time step540000\n",
      "Evaluation over 10 episodes: 2945.113  time step545000\n",
      "Evaluation over 10 episodes: 3240.704  time step550000\n",
      "Evaluation over 10 episodes: 2933.637  time step555000\n",
      "Evaluation over 10 episodes: 2901.818  time step560000\n",
      "Evaluation over 10 episodes: 2861.755  time step565000\n",
      "Evaluation over 10 episodes: 3177.065  time step570000\n",
      "Evaluation over 10 episodes: 3129.245  time step575000\n",
      "Evaluation over 10 episodes: 3262.387  time step580000\n",
      "Evaluation over 10 episodes: 3447.776  time step585000\n",
      "Evaluation over 10 episodes: 2572.223  time step590000\n",
      "Evaluation over 10 episodes: 2553.088  time step595000\n",
      "Evaluation over 10 episodes: 3361.592  time step600000\n",
      "Evaluation over 10 episodes: 2495.380  time step605000\n",
      "Evaluation over 10 episodes: 2731.573  time step610000\n",
      "Evaluation over 10 episodes: 3164.463  time step615000\n",
      "Evaluation over 10 episodes: 2718.659  time step620000\n",
      "Evaluation over 10 episodes: 3188.195  time step625000\n",
      "Evaluation over 10 episodes: 2886.866  time step630000\n",
      "Evaluation over 10 episodes: 3111.456  time step635000\n",
      "Evaluation over 10 episodes: 3149.997  time step640000\n",
      "Evaluation over 10 episodes: 3179.376  time step645000\n",
      "Evaluation over 10 episodes: 3345.277  time step650000\n",
      "Evaluation over 10 episodes: 3329.322  time step655000\n",
      "Evaluation over 10 episodes: 3397.661  time step660000\n",
      "Evaluation over 10 episodes: 2252.402  time step665000\n",
      "Evaluation over 10 episodes: 2544.404  time step670000\n",
      "Evaluation over 10 episodes: 3394.890  time step675000\n",
      "Evaluation over 10 episodes: 1874.599  time step680000\n",
      "Evaluation over 10 episodes: 2721.948  time step685000\n",
      "Evaluation over 10 episodes: 3327.226  time step690000\n",
      "Evaluation over 10 episodes: 3110.416  time step695000\n",
      "Evaluation over 10 episodes: 2945.205  time step700000\n",
      "Evaluation over 10 episodes: 2887.159  time step705000\n",
      "Evaluation over 10 episodes: 3048.074  time step710000\n",
      "Evaluation over 10 episodes: 2490.895  time step715000\n",
      "Evaluation over 10 episodes: 3105.164  time step720000\n",
      "Evaluation over 10 episodes: 2244.793  time step725000\n",
      "Evaluation over 10 episodes: 3034.799  time step730000\n",
      "Evaluation over 10 episodes: 2673.162  time step735000\n",
      "Evaluation over 10 episodes: 3029.807  time step740000\n",
      "Evaluation over 10 episodes: 3319.717  time step745000\n",
      "Evaluation over 10 episodes: 3224.301  time step750000\n",
      "Evaluation over 10 episodes: 3214.125  time step755000\n",
      "Evaluation over 10 episodes: 2680.418  time step760000\n",
      "Evaluation over 10 episodes: 3634.502  time step765000\n",
      "Evaluation over 10 episodes: 3784.802  time step770000\n",
      "Evaluation over 10 episodes: 3695.980  time step775000\n",
      "Evaluation over 10 episodes: 2725.049  time step780000\n",
      "Evaluation over 10 episodes: 3238.421  time step785000\n",
      "Evaluation over 10 episodes: 3582.303  time step790000\n",
      "Evaluation over 10 episodes: 3337.725  time step795000\n",
      "Evaluation over 10 episodes: 3429.166  time step800000\n",
      "Evaluation over 10 episodes: 1908.008  time step805000\n",
      "Evaluation over 10 episodes: 3730.309  time step810000\n",
      "Evaluation over 10 episodes: 3741.111  time step815000\n",
      "Evaluation over 10 episodes: 2263.040  time step820000\n",
      "Evaluation over 10 episodes: 1694.546  time step825000\n",
      "Evaluation over 10 episodes: 3787.560  time step830000\n",
      "Evaluation over 10 episodes: 3151.627  time step835000\n",
      "Evaluation over 10 episodes: 2957.363  time step840000\n",
      "Evaluation over 10 episodes: 2666.407  time step845000\n",
      "Evaluation over 10 episodes: 3536.751  time step850000\n",
      "Evaluation over 10 episodes: 3224.551  time step855000\n",
      "Evaluation over 10 episodes: 3620.500  time step860000\n",
      "Evaluation over 10 episodes: 3778.672  time step865000\n",
      "Evaluation over 10 episodes: 3762.217  time step870000\n",
      "Evaluation over 10 episodes: 3040.341  time step875000\n",
      "Evaluation over 10 episodes: 3888.296  time step880000\n",
      "Evaluation over 10 episodes: 3531.412  time step885000\n",
      "Evaluation over 10 episodes: 3525.326  time step890000\n",
      "Evaluation over 10 episodes: 3288.619  time step895000\n",
      "Evaluation over 10 episodes: 3100.438  time step900000\n",
      "Evaluation over 10 episodes: 3488.851  time step905000\n",
      "Evaluation over 10 episodes: 1849.075  time step910000\n",
      "Evaluation over 10 episodes: 3077.666  time step915000\n",
      "Evaluation over 10 episodes: 3683.017  time step920000\n",
      "Evaluation over 10 episodes: 3407.114  time step925000\n",
      "Evaluation over 10 episodes: 3074.935  time step930000\n",
      "Evaluation over 10 episodes: 3753.267  time step935000\n",
      "Evaluation over 10 episodes: 2966.036  time step940000\n",
      "Evaluation over 10 episodes: 3623.795  time step945000\n",
      "Evaluation over 10 episodes: 3513.136  time step950000\n",
      "Evaluation over 10 episodes: 2742.648  time step955000\n",
      "Evaluation over 10 episodes: 3689.187  time step960000\n",
      "Evaluation over 10 episodes: 2571.648  time step965000\n",
      "Evaluation over 10 episodes: 3719.684  time step970000\n",
      "Evaluation over 10 episodes: 3929.977  time step975000\n",
      "Evaluation over 10 episodes: 3831.246  time step980000\n",
      "Evaluation over 10 episodes: 3629.546  time step985000\n",
      "Evaluation over 10 episodes: 3903.773  time step990000\n",
      "Evaluation over 10 episodes: 3488.127  time step995000\n",
      "Evaluation over 10 episodes: 3955.920  time step1000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import json,os\n",
    "\n",
    "alg=\"TD3\"\n",
    "seed=3\n",
    "envName='Ant-v3'\n",
    "StepLimit=1000000\n",
    "start_timesteps=10000\n",
    "evaluationStep=5000\n",
    "batch_size=100\n",
    "\n",
    "def eval_policy(policy, env_name,eval_episodes=10):\n",
    "\teval_env = gym.make(env_name)\n",
    "\tavg_reward = 0.\n",
    "\tfor _ in range(eval_episodes):\n",
    "\t\tstate, _ = eval_env.reset()\n",
    "\t\tdone= False\n",
    "\t\ttruncuated= False\n",
    "\t\twhile (not done) and (not truncuated):\n",
    "\t\t\taction = policy.select_action(np.array(state))\n",
    "\t\t\tstate, reward, done,truncuated, _ = eval_env.step(action)\n",
    "\t\t\tavg_reward += reward\n",
    "\tavg_reward /= eval_episodes\n",
    "\treturn avg_reward\n",
    "\n",
    "\n",
    "env = gym.make(envName)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "state_max = env.observation_space.shape\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "kwargs = {\"state_dim\": state_dim,\"action_dim\": action_dim,\"max_action\": max_action,\"discount\": 0.99,\"tau\": 0.005,}\n",
    "kwargs[\"policy_noise\"] = 0.2 * max_action\n",
    "kwargs[\"noise_clip\"] = 0.5 * max_action\n",
    "kwargs[\"policy_freq\"] = 2\n",
    "policy = TD3(**kwargs)\n",
    "\n",
    "replay_buffer = ReplayBuffer(state_dim, action_dim)\n",
    "evaluations = [eval_policy(policy, envName)]\n",
    "time_step=0\n",
    "while (time_step<StepLimit):\n",
    "    state, _ = env.reset(seed=seed)\n",
    "    done = False\n",
    "    truncuated = False\n",
    "    while (not done) and (not truncuated):\n",
    "        if time_step < start_timesteps:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = (policy.select_action(np.array(state))\n",
    "                + np.random.normal(0, max_action * 0.1, size=action_dim)).clip(-max_action, max_action)\n",
    "        next_state, reward, done,truncuated, _ = env.step(action)\n",
    "        replay_buffer.add(state, action, reward,next_state, int(not(done)))\n",
    "        if time_step > start_timesteps:\n",
    "            policy.train(replay_buffer)\n",
    "        state = next_state\n",
    "        time_step+=1\n",
    "        if (time_step % evaluationStep) == 0:\n",
    "            avg_reward=eval_policy(policy,envName)\n",
    "            evaluations.append(avg_reward)\n",
    "            print(f\"Evaluation over {10} episodes: {avg_reward:.3f}  time step{time_step}\")\n",
    "variant = dict(algorithm=alg,env=envName,)\n",
    "if not os.path.exists(f\"./data/{envName}/{alg}/seed{seed}\"):\n",
    "    os.makedirs(f'./data/{envName}/{alg}/seed{seed}')\n",
    "with open(f'./data/{envName}/{alg}/seed{seed}/variant.json', 'w') as outfile:\n",
    "    json.dump(variant,outfile)\n",
    "data = np.array(evaluations)\n",
    "df = pd.DataFrame(data=data,columns=[\"Average Return\"]).reset_index()\n",
    "df['Timesteps'] = df['index'] * evaluationStep\n",
    "df['env'] = envName\n",
    "df['algorithm_name'] = alg\n",
    "df.to_csv(f'./data/{envName}/{alg}/seed{seed}/progress.csv', index = False)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11334.246115,
   "end_time": "2023-06-16T19:19:56.339765",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-16T16:11:02.093650",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
